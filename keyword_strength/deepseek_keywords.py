import json
import requests
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import os
from tqdm import tqdm
# é…ç½®DeepSeek API



def extract_keywords_with_deepseek(text):
    """ä½¿ç”¨DeepSeek APIæå–é›†æˆç”µè·¯é¢†åŸŸä¸“ä¸šå…³é”®è¯"""
    headers = {
        "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
        "Content-Type": "application/json"
    }

    prompt = f"""
    è¯·ä»ä»¥ä¸‹è‹±æ–‡æ‘˜è¦ä¸­æå–å‡ºé›†æˆç”µè·¯/åŠå¯¼ä½“ç›¸å…³çš„ä¸“ä¸šæœ¯è¯­æˆ–æŠ€æœ¯å…³é”®è¯ã€‚
    åªè¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œæ¯è¡Œä¸€ä¸ªï¼Œä¸è¦è§£é‡Šæˆ–å…¶ä»–å†…å®¹ã€‚

    æ–‡æœ¬å†…å®¹ï¼š
    {text}
    """

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "top_p": 0.1,
        "max_tokens": 150
    }

    try:
        response = requests.post(DEEPSEEK_API_URL, json=payload, headers=headers)
        response.raise_for_status()
        content = response.json()['choices'][0]['message']['content'].strip()
        return [line.strip().lower() for line in content.split('\n') if line.strip()]
    except (requests.exceptions.RequestException, KeyError, IndexError) as e:
        print(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return []


def read_json_file(file_path):
    with open(file_path, 'r', encoding='utf-8') as file:
        return json.load(file)


def extract_keywords_from_abstracts(data):
    keywords = []
    entries = data["chosen"] + data["filtered"]
    
    print("ğŸ§  æ­£åœ¨è°ƒç”¨ DeepSeek æå–å…³é”®è¯...")
    for entry in tqdm(entries, desc="ğŸ” å…³é”®è¯æå–è¿›åº¦", unit="abstract"):
        abstract = entry.get("abstract", "")
        if abstract:
            extracted = extract_keywords_with_deepseek(abstract)
            keywords.extend(extracted)
    return keywords


def count_keywords(keywords):
    return Counter(keywords)


def plot_histogram(counter):
    most_common = counter.most_common(20)
    words, counts = zip(*most_common)

    plt.figure(figsize=(10, 6))
    plt.bar(words, counts, color='skyblue')
    plt.xticks(rotation=45, ha='right')
    plt.xlabel('Keywords')
    plt.ylabel('Frequency')
    plt.title('Keyword Frequency Histogram (Top 20)')  # ğŸ‘ˆ åˆ é™¤äº† (DeepSeek)
    plt.tight_layout()
    plt.show()
def read_all_json_files(folder_path):
    all_data = {"chosen": [], "filtered": []}
    json_files = [f for f in os.listdir(folder_path) if f.endswith(".json")]
    
    print("ğŸ“š æ­£åœ¨è¯»å– JSON æ–‡ä»¶...")
    for filename in tqdm(json_files, desc="ğŸ“„ è¯»å–è¿›åº¦", unit="file"):
        file_path = os.path.join(folder_path, filename)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                all_data["chosen"].extend(data.get("chosen", []))
                all_data["filtered"].extend(data.get("filtered", []))
        except Exception as e:
            print(f"âš ï¸ è¯»å– {filename} å¤±è´¥: {e}")
    
    return all_data

def generate_wordcloud(counter, top_n=20):
    """ç”Ÿæˆè¯äº‘å›¾ï¼ŒåªåŒ…å«ç›´æ–¹å›¾ä¸­æ˜¾ç¤ºçš„å‰ top_n ä¸ªå…³é”®è¯"""
    most_common = counter.most_common(top_n)
    wordcloud_text = ' '.join([word + ' ' * count for word, count in most_common])

    wordcloud = WordCloud(
        width=800,
        height=400,
        background_color='white',
        font_path= None  # ä¸­æ–‡æ”¯æŒ
    ).generate(wordcloud_text)

    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Top {top_n} Keyword Word Cloud")  # ğŸ‘ˆ åˆ é™¤äº† (DeepSeek)
    plt.show()


if __name__ == "__main__":
    folder_path = 'D:/ai/ai_research_assistant/arxiv/output_llms'  # åŒ…å«å¤šä¸ª .json çš„æ–‡ä»¶å¤¹
    data = read_all_json_files(folder_path)
    keywords = extract_keywords_from_abstracts(data)
    counter = count_keywords(keywords)
    plot_histogram(counter)
    generate_wordcloud(counter)